---
layout: post
title: Dia 4 de 100 - Web Scraping com Python - Parte 3 de 3
---

Dando in√≠cio √† parte 3 de nossa jornada sobre Web Scraping com Python no dia 4 de 100, √© uma vez estando com nossos dados baixados e armazenados no _dataframe_ `df`, representando as estat√≠sticas anuais da liga norte-americana de basquete (NBA) extra√≠das do site [Sports Reference](https://www.sports-reference.com). Lembrando que os dados foram adquiridos segundo seus respectivos anos de ocorr√™ncia (2015 a 2019 - escolha do autor), manipularemos agora este _dataframe_ para extrair dele informa√ß√µes de interesse e mostrar exemplos de como usar e analisar estatisticamente seus resultados.

### Exemplo de uso dos dados

O primeiro e importante passo se executar no processo est√° relacionado a uma filtragem dos dados adquiridos, para evitar inconsist√™ncias ou duplicidades. Independentemente da confiabilidade da fonte, recomenda-se que esta etapa seja levada a cabo para qur nao haja erros ou incoer√™ncias nos resultados da an√°lise dos dados. 

#### Filtragem de dados

Neste ponto, note-se que, na tabela original no site, h√° nomes de colunas que se repetem em uma mesma tupla. Uma forma de eliminar essas duplicidades do _dataframe_ da seguinte maneira:

```python
# Exemplo com a coluna 'Rk'
# Armazenando os valores de _index_ a serem eliminados.
drop_indexes = df[df['Rk'] == 'Rk'].index
# Eliminando os valores de __index_ armazenados acima
df.drop(drop_indexes, inplace=True) 
```

#### Homogeneiza√ß√£o dos tipos de dados

O pr√≥ximo passo ap√≥s a filtragem √© a convers√£o dos tipos de dados para homogeneizar valores e tipos no _dataframe_ - exemplo: converter valores num√©ricos armazenados em forma de texto para o formato num√©rico.

```python
numeric_cols = df.columns.drop(['Player','Pos','Tm'])
df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric)
```

#### Bibliotecas utilizadas

* `Matplotlib`; e
* `Seaborn`. <br />
Ambas as bibliotecas foram utilizadas para gerar visualiza√ß√µes.

#### Exemplo de plotagem de dados - An√°lise da m√©dia de arremessos de 3 pontos convertidos por ano na NBA

E extrato de c√≥digo a seguir plota um gr√°fico com a descri√ß√£o acima.

```python
sns.barplot(x=df['Year'], y=df['3PA'])
plt.show()
```

Sua sa√≠da para este contexto √©:

<img src="http://euriconicacio.github.io/blog/images/d4of100_img1.png" width="60%"><br />
![](/images/d4of100_img1.png)
###### _Gr√°fico de m√©dia de tentativas de arremessos de 3 pontos por temporada_

A partir da an√°lise do gr√°fico anterior, nota-se que o volume de bolas de 3 aumentou ano ap√≥s ano (exce√ß√£o feita √† an√°lise prejudicada entre 2017 e 2018). Dessa forma, poderiamos questionar: quais s√£o os jogadores que mais acertaram nesse per√≠odo? Verifiquemos os 5 maiores arremessadores com manipula√ß√µes do `Pandas`. O extrato de c√≥digo abaixo traria a resposta:

```python
# Ordenar o dataframe por 3PA em ordem decrescente
ord_df = df.sort_values(by=['3P'], axis=0, ascending=False)
# Exibe os 5 maiores arremessadores
ord_df[['Player', '3P', 'Year']].head()
```
### Conclus√£o

Bom, espero que este passo-a-passo tenha elucidado o funcionamento do processo "b√°sico" de Web Scraping com Python e possa serv ir de pontap√© inicial para um estudo mais aprofundado sobre o tema. Como disse inicialmente, o intuito nunca foi esgotar o tema, mas sim prover um ponto de partida que desperte o interesse no t√≥pico. 

Em caso de alguma eventual d√∫vida, sigo √† disposi√ß√£o para discutir o assunto.

Ahh.. E, para amanh√£, vamos para um tema mais _hackingtheworld-like_. üòú

#100daysofcode #day4of100 #programming #coding #code #python #developer #coder #programmer #peoplewhocode #hacking #ethicalhacking #hacktheworld #webscraping
